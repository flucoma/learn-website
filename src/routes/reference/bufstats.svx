---
title: BufStats
blurb: Statistical analysis of buffer channels
tags: 
    - buffer
    - statistics
    - stats
    - descriptor
flair: reference
category: Analyse Data
---

<script>
    import CodeBlock from '$lib/components/CodeBlock.svelte';
    import { Tabs, TabList, TabPanel, Tab } from '$lib/components/tabs/tabs';
    import Image from '$lib/components/Image.svelte';
    import ResourceLink from '$lib/components/ResourceLink.svelte';
    import IndentNote from '$lib/components/IndentNote.svelte';
</script>

BufStats statistically summarises a set of values that are in a buffer channel, returning seven statistical properties: the [mean](#mean), [standard deviation](#standard-deviation), [skewness](#skewness), [kurtosis](#kurtosis), [low](#low), [middle](#middle), and [high](#high) values. The mean and median (received when middle = 50) are a measure of the central tendency of the data, while the others offer a measure of the variability in the data.

A buffer typically holds time-series information as "frames," either in the form of audio samples (as an audio buffer for playback) or as a series of audio descriptors created by an analysis process (as is the case with FluCoMa's buffer-based analyses). If different time-series (such as slices) are all a different number of frames long, it may be difficult to compare them. The statistical summary provided by BufStats can be useful for comparing these time series (for example, the mean analysis value from one time-series can be compared to the mean analysis value from another time series even if the original time series are different lengths).

In addition to computing these statistical representations on the original buffer channel, BufStats can also:

* compute these statistics on [derivatives](#derivatives) of the original time-series with the `numDerivs` parameter
* apply [weights](#weights) to the various frames to produce a weighted statistical summary using a `weights` buffer
* find and remove [outliers](#outliers) from the frames included in the statistical calculations with `outliersCutoff`

<IndentNote type='pointer'>

While it can be difficult to discern how to use some of these analyses practically (i.e., what does the kurtosis of the first derivative of spectral centroid indicate musically?) these statistical summaries can sometimes represent differences between analyses that dimensionality reduction and machine learning algorithms can pick up on. Including these statistical descriptions in training or analysis may provide better distinction between data points.

</IndentNote>

The stats output buffer of FluidBufStats will have the same number of channels as the input buffer, each one containing the statistics of it's corresponding channel in the input buffer. Because the dimension of time is summarised statistically, the frames in the stats buffer do not represent time as they normally would. The first seven frames in every channel of the stats buffer will have the seven statistics computed on the input buffer channel. After these first seven frames, there will be seven more frames for each derivative requested, each containing the seven statistical summaries for the corresponding derivative.

## Mean

The average value of the data. This is calculated by adding up all the numbers and the dividing by how many numbers there are. The mean can be used to describe the central tendency of a set of values. 

## Standard Deviation

Standard deviation describes of the amount of variation in the data (using the same units as the data itself). A lower standard deviation indicates that the values are generally nearer to the mean, while a higher standard deviation indicates that many values are more spread out, further from the mean.

Standard deviation could also help calculate where most of our data points can be found. If a collection of values is [normally distributed](#distribution-and-histograms), one can expect to find ~68% of the data within one standard deviation of the mean. For example if a [SpectralShape](/reference/spectralshape)'s spectral centroid time-series is analysed and BufStats returns a mean of 8000 Hz and a standard deviation off 1000 Hz, one can estimate that ~68% of the spectral centroids in that time series fall between 7000 and 9000 Hz (8000 Hz ± 1000 Hz). Similarly, one could estimate that ~95% of the data will fall within two standard deviations of the mean and ~99.7% will fall within three standard deviations of the mean. Keep in mind that if the data is not normally distributed, this will not hold true.

<Image
src="Standard_deviation_diagram.png"
label="When data is normally distributed, it follows the 68/95/99.7 rule, indicating how much of the data is found within standard deviations of the mean. (image reproduced from [Wikipedia](https://en.wikipedia.org/wiki/Standard_deviation))"
/>

## Skewness

Skewness indicates the asymmetry of the distribution of the data. If the data is perfectly normally distributed the left and right sides of the mean will be mirrored, and skewness will be 0. If either side has a longer "tail" than the other, the skewness will not be zero. If the left side (lower values) have a longer tail, the skewness will be less than 0, if the right side (higher values) have a longer tail, the skewness will be greater than 0. The larger the tail, the larger the magnitude of the skewness value.

<Image
src="skewness.png"
label="Data distributions with a larger tail to the left have a negative skewness while data distributions with a larger tail to the right have a positive skewness. (image reproduced from [Wikipedia](https://en.wikipedia.org/wiki/Skewness))  "
/>

## Kurtosis

Kurtosis describes the degree to which outliers are present in the data, sometimes described as whether the tails (extremities) are "light" or "heavy." While a normal distribution has a kurtosis of 3, distributions with "lighter" tails (fewer and/or less extreme outliers) will be between 1 and 3, and distributions with "heavier" tails (more and/or more extreme outliers) will be greater than 3 (and can go up to infinity).  

One can see in the image below that the pink rectangle-shaped distribution function has the lowest kurtosis (1.8) because it does not have outliers, all the data falls within the narrow range of the rectangle. The second lowest kurtosis (2) is the blue distribution function which also doesn't have "tails" that spread out on either side. As the kurtosis increases (all the way to 6 for the red distribution function), notice how the tails end up being "heavier," or "thicker" and can be seen to spread out farther beyond the mean. 

<Image
src="Standard_symmetric_distributions-01.jpg"
label="Kurtosis values (shown in the upper right hand corner) for various symmetric distributions. (image modified from [Wikipedia](https://en.wikipedia.org/wiki/Kurtosis))"
/>

Although, [it doesn't hold true for all data](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4321753/pdf/nihms-599845.pdf), kurtosis is sometimes described as the "peakedness" of a distribution. In the chart above, one can see how distribution functions with higher kurtosis are also "peakier," while the distributions with lower kurtosis are "flatter."

## Low

The value returned will be the data point at the [percentile](#percentiles) indicated by the ``low`` parameter (between 0 and 100). The default of 0 will return the the smallest value in the data. It may be useful to use this statistical description to consider particular extremities in an analysis time-series. For example considering the smallest pitch confidence value in an analysis could indicate if there are _any_ moments in the analysis that get _unpitched_ and if so, to what degree. 

## Middle

The value returned will be the data point at the [percentile](#percentiles) indicated by the ``middle`` parameter (between 0 and 100). The default value of 50 will return the median value. The median is the middle value when all the numbers are sorted in order. This provides a measure of central tendency different from the mean. The median is not affected by extreme outliers, which can decrease how useful a mean is for understanding central tendency.

## High

The value returned will be the data point at the [percentile](#percentiles) indicated by the ``high`` parameter (between 0 and 100). The default value of 100 will return the largest value in the data. It may be useful to use this statistical description for analyses in which the largest value has the most impact on a listener's perception. For example, how loud one perceives a drum hit to be may be better correlated with the maximum loudness instead of the mean loudness, which will be brought down by the quieter parts of the decay tail and any silence that exists in the sound slice. (See [Loudness](/reference/loudness))

# Percentiles

The values returned as [low](#low), [middle](#middle), and [high](#high) are percentiles values from the dataset (specified by the ``low``, ``middle``, and ``high`` parameters between 0 and 100). A percentile is a value at or below which a certain percentage of the values in the data will fall. For example, if the 15th percentile is 3000, that means that 15% of the values in the data are equal to or below 3000. The 50th percentile indicates the value which splits the data in half. This is also called the median. The 0th percentile will return the smallest value in the data and the 100th percentile will return the largest value in the data. When the number of values don't make clear which point from the data should be used, the [nearest rank method](https://en.wikipedia.org/wiki/Percentile) is used.

# Derivatives

Setting the parameter `numDerivs` > 0 will return the same seven statistics computed on consecutive derivatives of the channel's time-series. The derivative of a time-series is computed by finding the _difference_ between each consecutive value in a series. For example, the derivative of the input time-series in the top row is seen in the bottom row:

| A time-series and it's derivative |
|:---------------------|:--:|:--:|:---:|:--:|:---:|:---:|:--:|:--:|:--:|
| Original Time-Series | 10 | 15 | 30  | 20 | 25  | 12  | 0  | 24 | 40 |
| First Derivative     | 5  | 15 | -10 | 5  | -13 | -12 | 24 | 16 |    |

---

Note that the derivative has one fewer value than the original series because each value represents the amount and direction of change between two adjacent values in the original. To find the second derivative, BufStats computes the derivative of the first derivative:

| A time-series and two derivatives |
|:---------------------|:--:|:---:|:---:|:---:|:---:|:---:|:--:|:--:|:--:|
| Original Time-Series | 10 | 15  | 30  | 20  | 25  | 12  | 0  | 24 | 40 |
| First Derivative     | 5  | 15  | -10 | 5   | -13 | -12 | 24 | 16 |    |
| Second Derivative    | 10 | -25 | 15  | -18 | 1   | 36  | -8 |    |    |

---

After computing the number of derivatives indicated by the user (with `numDerivs`) BufStats calculates the same seven statistical summaries on these new series of numbers: mean, standard deviation, skewness, kurtosis, low, middle, and high.

### A musical example

Derivatives can indicate how a time-series (of a descriptor for example) changes over time. Consider the two sounds below. The top one is a snare hit with its loudness analysis overlaid. The bottom is the same snare hit but reversed. The mean [Loudness](/reference/loudness) for both of these is about -33 dB, therefore it's not useful to distinguish the two. Looking at the derivative can help. In the top chart one can see that the change between adjacent loudness measures tends to be negative (go down), so the derivative will be mostly negative numbers--and therefore the derivative mean will be negative. In the bottom chart, the change tends to be positive (go up), so the derivative will be mostly positive numbers--and therefore the derivative mean will be positive. Sure enough, the mean derivative for the top chart is -0.8 dB and the mean derivative for the bottom chart is 0.9 dB. These numbers can now be useful in distinguishing these two sounds.

<Image
src="00_loudness_derivative.jpg"
label="A single snare hit and its loudness analysis."
/>

<Image
src="01_reversed_loudness_derivative.jpg"
label="A reversed snare hit and its loudness analysis."
/>

# Weights

The ``weights`` parameter can be passed a buffer, the values of which will be used for relative weighting of each corresponding frame in the ``source`` buffer. This will create "weighted" statistics where some values in the data have more impact on the resulting statistical summary than others. All seven of the resulting statistics may be affected by using the weights. 

This can be useful for weighting certain moments in descriptor time-series by the value of other descriptors. For example, one might want to weigh the pitch analysis with the pitch confidence descriptor so the resulting mean pitch value is more strongly influenced by moments in the analysis when the pitch confidence is high. Similarly, one might want to weigh a descriptor time-series by amplitude so the louder moments of sound have greater impact on the resulting statistical summary than quieter moments.

<IndentNote type='pointer'>

For an example of using a ``weights`` buffer to influence the statistical summary in a musical way, visit the [Weighing Stats]() Overview.

</IndentNote>

Not providing a ``weights`` buffer will cause all the frames to be considered equally. Any negative values in the ``weights`` buffer will be treated as a weight of 0. The provided ``weights`` buffer must satisfy all of the following conditions:

* a single-channel
* exactly the same amount of frames as ``source`` (each frame in ``weights`` will be the weight amount for the corresponding frame in ``source``)

# Outliers

The parameter ``outliersCutoff`` is a ratio of the _interquartile_ range (IQR) that defines a range from the median, outside of which data will be considered an outlier and not used to compute the statistical summary. 

For each frame, if a single value in any channel of that frame is considered an outlier (when compared to the rest of the values in it's channel), the whole frame (on all channels) will not be used for statistical calculations. The default of -1 bypasses this function, keeping all frames in the statistical measurements. For more information on this statistical process, please refer to the concept of inter quantile range IQR and how the whiskers of a box plot are computed here (https://en.wikipedia.org/wiki/Box_plot)

# Distribution and Histograms  

Many of the statistical summaries that BufStats computes are intended to provide some insight on how the data is distributed across the range that it covers. A distribution is often viewed as a histogram, which divides the range covered by the data into discrete bins and then shows how many individual data points fall within each bin.

<Image
src="histogram.png"
label="A histogram of 25 bins showing the distribution of MFCC 2 values in an analysis of Nicol-LoopE-M.wav"
/>

Sometimes the distribution is represented as a curve which can be called a distribution function. This can be thought of as a smoothed out version of a histogram. It shows the likelihood that a data point will exist for any given value in a range. 

<Image
src="distribution_function.png"
label="Distribution function based on the same data as the histogram above."
/>

<IndentNote type='pointer'>

Keep in mind that the distribution functions are not the functions being analysed by BufStats, but instead represent the distribution of the values in the buffer channel being analysed by BufStats.

</IndentNote>

## Normal Distribution

Normal distribution is a technical term meaning that the distribution of data follows the 68/95/99.7 rule. This rule states that ~68% of the data falls within one standard deviation of the mean, ~95% of the data falls within two standard deviations of the mean, and ~99.7% falls within three standard deviations of the mean. Sometimes a normal distribution is referred to as a "bell curve" because the shape of the distribution function looks like a bell. Use the example code below to see the distribution of dimensions in a dataset and how much they look like a bell curve.

<Image
src="Standard_deviation_diagram.png"
label="When data is normally distributed, it follows the 68/95/99.7 rule, indicating how much of the data is found within standard deviations of the mean. (image reproduced from [Wikipedia](https://en.wikipedia.org/wiki/Standard_deviation))"
/>

### Example code to check the distribution of dimensions in a [DataSet](/reference/dataset) using a histogram

<Tabs>
    <TabList>
        <Tab>Max</Tab>
        <Tab>SuperCollider</Tab>
    </TabList>
    <TabPanel>

    TODO

    </TabPanel>
    <TabPanel>
    
<CodeBlock>

```
~distribution = {
	arg dataset, steps = 100;
	dataset.dump({
		arg dict;
		var data = dict["data"].values.flop;
		var histograms = data.collect{arg dim; dim.histo(steps)};
		fork({
			var win = Window("Distributions",Rect(0,0,800,820));
			var plotter = Plotter("Distributions",Rect(0,20,win.bounds.width,win.bounds.height-20),win);
			plotter.plotMode_(\bars);
			EZSlider(win,Rect(0,0,win.bounds.width,20),"Dimension:",ControlSpec(0,histograms.size-1,step:1),{
				arg sl;
				plotter.value_(histograms[sl.value.asInteger]);
			},0,true,80);
			win.front;
		},AppClock);
	});
};
```

</CodeBlock>

    </TabPanel>
</Tabs>

---  

# Related Resources

<ResourceLink
title='Kurtosis as Peakedness, 1905 – 2014. R.I.P.'
url='https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4321753/pdf/nihms-599845.pdf'
blurb='Paper by Peter H. Westfall (2014) describing a common misconception about kurtosis.'
/>
